{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Week 6:  Loading and Cleaning Data\n",
    "\n",
    "Today's lecture will cover the basics of loading data into R and cleaning it. In class and online tutorials (like DataCamp) the datasets you're given are impeccably clean and ready to go immediately. In practice this is simply not the case--75% of a data scientist's time is used for getting and cleaning data prior to modeling! So today you will learn the basics of loading common static data formats and cleaning the data using [regular expressions]().\n",
    "\n",
    "Up until now the instructors have been writing the code for reading and loading data to R for you. From this tutorial forward we will leave the loading to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data Formats\n",
    "\n",
    "<strong><a href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a></strong> stands for Comma-Seperated Values. These are text files, where each line is an observation and the variables are seperated by commas. In a <code>.csv</code> file, the <strong>delimiter</strong> is the comma. There are similar offshoots of this format: tab-seperated values or a general delimiter-seperated values. If a <code>.csv</code> file includes the header, it is entered as the first line in the file. Also notice in the sample that there is a comma included in the <code>name</code> field--how is that possible?\n",
    "\n",
    "    \"Date\",\"Name\",\"Grade\"\n",
    "    \"25 May\",\"Bloggs, Fred\",\"C\"\n",
    "    \"25 May\",\"Doe, Jane\",\"B\"\n",
    "    \"15 July\",\"Bloggs, Fred\",\"A\"\n",
    "    \"15 April\",\"Muniz, Alvin \"\"Hank\"\"\",\"A\"\n",
    "    \n",
    "<strong><a href=\"http://json.org/\">JSON</a></strong> stands for Javascipt Object Notation. This data storage format is very common in application and website databases because it is lightweight and flexible. The example below holds two records, one for John Smith and another for Jason Freeberg. As you can see, the two records have different numbers of fields--the first does not have a <code>middlename</code> and the second does not have <code>postalCode2</code>. If we attempted to store this in a tabular format, we would have many missing entries and waste space.\n",
    "\n",
    "    {\n",
    "      \"firstName\": \"John\",\n",
    "      \"lastName\": \"Smith\",\n",
    "      \"isAlive\": true,\n",
    "      \"age\": 25,\n",
    "      \"address\": {\n",
    "        \"streetAddress\": \"21 2nd Street\",\n",
    "        \"city\": \"New York\",\n",
    "        \"state\": \"NY\",\n",
    "        \"postalCode1\": 3100\n",
    "        \"postalCode2\": 10021\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"firstName\": \"Jason\",\n",
    "      \"middleName\": \"Robert\",\n",
    "      \"lastName\": \"Freeberg\",\n",
    "      \"isAlive\": true,\n",
    "      \"age\": 21,\n",
    "      \"address\": {\n",
    "        \"streetAddress\": \"6760 Sabado\",\n",
    "        \"streetAddress2\": \"Unit B\"\n",
    "        \"city\": \"Isla Vista\",\n",
    "        \"state\": \"CA\",\n",
    "        \"postalCode1\": 93117\n",
    "      }\n",
    "    }\n",
    "\n",
    "## Loading Data in R\n",
    "\n",
    "Since R is a statistical software, and statistics is the analysis of data, it makes sense that R has many functions built in for loading data. R's general <code>read.table()</code> function will read tabular data but requires that you specify the file's delimiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>season</th><th scope=col>week_num</th><th scope=col>day_of_week</th><th scope=col>gametime_local</th><th scope=col>home_team</th><th scope=col>away_team</th><th scope=col>home_score</th><th scope=col>away_score</th><th scope=col>OT_flag</th><th scope=col>arrests</th><th scope=col>division_game</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2011           </td><td> 1             </td><td>Sunday         </td><td>1:15:00 PM     </td><td>Arizona        </td><td>Carolina       </td><td>28             </td><td>21             </td><td>               </td><td>5              </td><td>n              </td></tr>\n",
       "\t<tr><td>2011           </td><td> 4             </td><td>Sunday         </td><td>1:05:00 PM     </td><td>Arizona        </td><td>New York Giants</td><td>27             </td><td>31             </td><td>               </td><td>6              </td><td>n              </td></tr>\n",
       "\t<tr><td>2011           </td><td> 7             </td><td>Sunday         </td><td>1:05:00 PM     </td><td>Arizona        </td><td>Pittsburgh     </td><td>20             </td><td>32             </td><td>               </td><td>9              </td><td>n              </td></tr>\n",
       "\t<tr><td>2011           </td><td> 9             </td><td>Sunday         </td><td>2:15:00 PM     </td><td>Arizona        </td><td>St. Louis      </td><td>19             </td><td>13             </td><td>OT             </td><td>6              </td><td>y              </td></tr>\n",
       "\t<tr><td>2011           </td><td>13             </td><td>Sunday         </td><td>2:15:00 PM     </td><td>Arizona        </td><td>Dallas         </td><td>19             </td><td>13             </td><td>OT             </td><td>3              </td><td>n              </td></tr>\n",
       "\t<tr><td>2011           </td><td>14             </td><td>Sunday         </td><td>2:05:00 PM     </td><td>Arizona        </td><td>San Francisco  </td><td>21             </td><td>19             </td><td>               </td><td>4              </td><td>y              </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       " season & week\\_num & day\\_of\\_week & gametime\\_local & home\\_team & away\\_team & home\\_score & away\\_score & OT\\_flag & arrests & division\\_game\\\\\n",
       "\\hline\n",
       "\t 2011            &  1              & Sunday          & 1:15:00 PM      & Arizona         & Carolina        & 28              & 21              &                 & 5               & n              \\\\\n",
       "\t 2011            &  4              & Sunday          & 1:05:00 PM      & Arizona         & New York Giants & 27              & 31              &                 & 6               & n              \\\\\n",
       "\t 2011            &  7              & Sunday          & 1:05:00 PM      & Arizona         & Pittsburgh      & 20              & 32              &                 & 9               & n              \\\\\n",
       "\t 2011            &  9              & Sunday          & 2:15:00 PM      & Arizona         & St. Louis       & 19              & 13              & OT              & 6               & y              \\\\\n",
       "\t 2011            & 13              & Sunday          & 2:15:00 PM      & Arizona         & Dallas          & 19              & 13              & OT              & 3               & n              \\\\\n",
       "\t 2011            & 14              & Sunday          & 2:05:00 PM      & Arizona         & San Francisco   & 21              & 19              &                 & 4               & y              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  season week_num day_of_week gametime_local home_team away_team      \n",
       "1 2011    1       Sunday      1:15:00 PM     Arizona   Carolina       \n",
       "2 2011    4       Sunday      1:05:00 PM     Arizona   New York Giants\n",
       "3 2011    7       Sunday      1:05:00 PM     Arizona   Pittsburgh     \n",
       "4 2011    9       Sunday      2:15:00 PM     Arizona   St. Louis      \n",
       "5 2011   13       Sunday      2:15:00 PM     Arizona   Dallas         \n",
       "6 2011   14       Sunday      2:05:00 PM     Arizona   San Francisco  \n",
       "  home_score away_score OT_flag arrests division_game\n",
       "1 28         21                 5       n            \n",
       "2 27         31                 6       n            \n",
       "3 20         32                 9       n            \n",
       "4 19         13         OT      6       y            \n",
       "5 19         13         OT      3       n            \n",
       "6 21         19                 4       y            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in readLines(jsonFile):\n",
      "“incomplete final line found on 'http://api.worldbank.org/country?per_page=10&region=OED&lendingtype=LNX&format=json'”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ :List of 4\n",
      "  ..$ page    : num 1\n",
      "  ..$ pages   : num 4\n",
      "  ..$ per_page: chr \"10\"\n",
      "  ..$ total   : num 31\n",
      " $ :List of 10\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"AUS\"\n",
      "  .. ..$ iso2Code   : chr \"AU\"\n",
      "  .. ..$ name       : chr \"Australia\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"EAS\"\n",
      "  .. .. ..$ value: chr \"East Asia & Pacific\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Canberra\"\n",
      "  .. ..$ longitude  : chr \"149.129\"\n",
      "  .. ..$ latitude   : chr \"-35.282\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"AUT\"\n",
      "  .. ..$ iso2Code   : chr \"AT\"\n",
      "  .. ..$ name       : chr \"Austria\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Vienna\"\n",
      "  .. ..$ longitude  : chr \"16.3798\"\n",
      "  .. ..$ latitude   : chr \"48.2201\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"BEL\"\n",
      "  .. ..$ iso2Code   : chr \"BE\"\n",
      "  .. ..$ name       : chr \"Belgium\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Brussels\"\n",
      "  .. ..$ longitude  : chr \"4.36761\"\n",
      "  .. ..$ latitude   : chr \"50.8371\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"CAN\"\n",
      "  .. ..$ iso2Code   : chr \"CA\"\n",
      "  .. ..$ name       : chr \"Canada\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"NAC\"\n",
      "  .. .. ..$ value: chr \"North America\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Ottawa\"\n",
      "  .. ..$ longitude  : chr \"-75.6919\"\n",
      "  .. ..$ latitude   : chr \"45.4215\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"CHE\"\n",
      "  .. ..$ iso2Code   : chr \"CH\"\n",
      "  .. ..$ name       : chr \"Switzerland\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Bern\"\n",
      "  .. ..$ longitude  : chr \"7.44821\"\n",
      "  .. ..$ latitude   : chr \"46.948\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"CZE\"\n",
      "  .. ..$ iso2Code   : chr \"CZ\"\n",
      "  .. ..$ name       : chr \"Czech Republic\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Prague\"\n",
      "  .. ..$ longitude  : chr \"14.4205\"\n",
      "  .. ..$ latitude   : chr \"50.0878\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"DEU\"\n",
      "  .. ..$ iso2Code   : chr \"DE\"\n",
      "  .. ..$ name       : chr \"Germany\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Berlin\"\n",
      "  .. ..$ longitude  : chr \"13.4115\"\n",
      "  .. ..$ latitude   : chr \"52.5235\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"DNK\"\n",
      "  .. ..$ iso2Code   : chr \"DK\"\n",
      "  .. ..$ name       : chr \"Denmark\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Copenhagen\"\n",
      "  .. ..$ longitude  : chr \"12.5681\"\n",
      "  .. ..$ latitude   : chr \"55.6763\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"ESP\"\n",
      "  .. ..$ iso2Code   : chr \"ES\"\n",
      "  .. ..$ name       : chr \"Spain\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Madrid\"\n",
      "  .. ..$ longitude  : chr \"-3.70327\"\n",
      "  .. ..$ latitude   : chr \"40.4167\"\n",
      "  ..$ :List of 10\n",
      "  .. ..$ id         : chr \"EST\"\n",
      "  .. ..$ iso2Code   : chr \"EE\"\n",
      "  .. ..$ name       : chr \"Estonia\"\n",
      "  .. ..$ region     :List of 2\n",
      "  .. .. ..$ id   : chr \"ECS\"\n",
      "  .. .. ..$ value: chr \"Europe & Central Asia\"\n",
      "  .. ..$ adminregion:List of 2\n",
      "  .. .. ..$ id   : chr \"\"\n",
      "  .. .. ..$ value: chr \"\"\n",
      "  .. ..$ incomeLevel:List of 2\n",
      "  .. .. ..$ id   : chr \"HIC\"\n",
      "  .. .. ..$ value: chr \"High income\"\n",
      "  .. ..$ lendingType:List of 2\n",
      "  .. .. ..$ id   : chr \"LNX\"\n",
      "  .. .. ..$ value: chr \"Not classified\"\n",
      "  .. ..$ capitalCity: chr \"Tallinn\"\n",
      "  .. ..$ longitude  : chr \"24.7586\"\n",
      "  .. ..$ latitude   : chr \"59.4392\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'firstRecord' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'firstRecord' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Package for working with JSON\n",
    "#install.packages(\"rjson\")\n",
    "library(rjson)\n",
    "\n",
    "# Let's load last week's data as a refresher\n",
    "arrests <- read.table(\"nfl_arrests.csv\", header=T, sep=\",\")\n",
    "head(arrests)\n",
    "\n",
    "# Now let's try a JSON collection from the internet\n",
    "jsonFile <- \"http://api.worldbank.org/country?per_page=10&region=OED&lendingtype=LNX&format=json\"\n",
    "jsonDoc <- fromJSON(paste(readLines(jsonFile), collapse=\"\"))\n",
    "str(jsonDoc)\n",
    "firstRecord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>season</th><th scope=col>week_num</th><th scope=col>day_of_week</th><th scope=col>gametime_local</th><th scope=col>home_team</th><th scope=col>away_team</th><th scope=col>home_score</th><th scope=col>away_score</th><th scope=col>OT_flag</th><th scope=col>arrests</th><th scope=col>division_game</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>466</th><td>2011           </td><td>12             </td><td>Sunday         </td><td>7:20:00 PM     </td><td>Kansas City    </td><td>123Pittsburgh  </td><td> 9             </td><td>13             </td><td>               </td><td> 0             </td><td>n.             </td></tr>\n",
       "\t<tr><th scope=row>1000</th><td>2015           </td><td> 2             </td><td>Sundayoops!    </td><td>1:00:00 PM     </td><td>Washington     </td><td>St. Louis      </td><td>24             </td><td>10             </td><td>               </td><td> 0             </td><td>nv             </td></tr>\n",
       "\t<tr><th scope=row>529</th><td>2015           </td><td>16             </td><td>Sunday         </td><td>1:00:00 PM     </td><td>Miami          </td><td>Indianapolis   </td><td>12             </td><td>18             </td><td>               </td><td> 0             </td><td>nd             </td></tr>\n",
       "\t<tr><th scope=row>996</th><td>2014           </td><td>14             </td><td>Sundayoops!    </td><td>1:00:00 PM     </td><td>Washington     </td><td>St. Louis      </td><td> 0             </td><td>24             </td><td>               </td><td> 3             </td><td>n3             </td></tr>\n",
       "\t<tr><th scope=row>577</th><td>2011           </td><td>15             </td><td>Sunday         </td><td>1:00:00 PM     </td><td>New York Giants</td><td>Washington     </td><td>10             </td><td>23             </td><td>               </td><td>31             </td><td>yyy            </td></tr>\n",
       "\t<tr><th scope=row>689</th><td>2011           </td><td> 4             </td><td>Sunday         </td><td>1:00:00 PM     </td><td>Philadelphia   </td><td>San Francisco  </td><td>23             </td><td>24             </td><td>               </td><td> 5             </td><td>n3             </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllll}\n",
       "  & season & week\\_num & day\\_of\\_week & gametime\\_local & home\\_team & away\\_team & home\\_score & away\\_score & OT\\_flag & arrests & division\\_game\\\\\n",
       "\\hline\n",
       "\t466 & 2011            & 12              & Sunday          & 7:20:00 PM      & Kansas City     & 123Pittsburgh   &  9              & 13              &                 &  0              & n.             \\\\\n",
       "\t1000 & 2015            &  2              & Sundayoops!     & 1:00:00 PM      & Washington      & St. Louis       & 24              & 10              &                 &  0              & nv             \\\\\n",
       "\t529 & 2015            & 16              & Sunday          & 1:00:00 PM      & Miami           & Indianapolis    & 12              & 18              &                 &  0              & nd             \\\\\n",
       "\t996 & 2014            & 14              & Sundayoops!     & 1:00:00 PM      & Washington      & St. Louis       &  0              & 24              &                 &  3              & n3             \\\\\n",
       "\t577 & 2011            & 15              & Sunday          & 1:00:00 PM      & New York Giants & Washington      & 10              & 23              &                 & 31              & yyy            \\\\\n",
       "\t689 & 2011            &  4              & Sunday          & 1:00:00 PM      & Philadelphia    & San Francisco   & 23              & 24              &                 &  5              & n3             \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | season | week_num | day_of_week | gametime_local | home_team | away_team | home_score | away_score | OT_flag | arrests | division_game | \n",
       "|---|---|---|---|---|---|\n",
       "| 466 | 2011            | 12              | Sunday          | 7:20:00 PM      | Kansas City     | 123Pittsburgh   |  9              | 13              |                 |  0              | n.              | \n",
       "| 1000 | 2015            |  2              | Sundayoops!     | 1:00:00 PM      | Washington      | St. Louis       | 24              | 10              |                 |  0              | nv              | \n",
       "| 529 | 2015            | 16              | Sunday          | 1:00:00 PM      | Miami           | Indianapolis    | 12              | 18              |                 |  0              | nd              | \n",
       "| 996 | 2014            | 14              | Sundayoops!     | 1:00:00 PM      | Washington      | St. Louis       |  0              | 24              |                 |  3              | n3              | \n",
       "| 577 | 2011            | 15              | Sunday          | 1:00:00 PM      | New York Giants | Washington      | 10              | 23              |                 | 31              | yyy             | \n",
       "| 689 | 2011            |  4              | Sunday          | 1:00:00 PM      | Philadelphia    | San Francisco   | 23              | 24              |                 |  5              | n3              | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     season week_num day_of_week gametime_local home_team       away_team    \n",
       "466  2011   12       Sunday      7:20:00 PM     Kansas City     123Pittsburgh\n",
       "1000 2015    2       Sundayoops! 1:00:00 PM     Washington      St. Louis    \n",
       "529  2015   16       Sunday      1:00:00 PM     Miami           Indianapolis \n",
       "996  2014   14       Sundayoops! 1:00:00 PM     Washington      St. Louis    \n",
       "577  2011   15       Sunday      1:00:00 PM     New York Giants Washington   \n",
       "689  2011    4       Sunday      1:00:00 PM     Philadelphia    San Francisco\n",
       "     home_score away_score OT_flag arrests division_game\n",
       "466   9         13                  0      n.           \n",
       "1000 24         10                  0      nv           \n",
       "529  12         18                  0      nd           \n",
       "996   0         24                  3      n3           \n",
       "577  10         23                 31      yyy          \n",
       "689  23         24                  5      n3           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use read.table() to import \"arrests.txt\"\n",
    "\n",
    "#dirtyData <- read.table(<FILL-IN>)\n",
    "dirtyData <- read.table(\"arrests.txt\", header=T, sep=\"\\t\")\n",
    "head(dirtyData)\n",
    "\n",
    "# Hint: open the file in a text editor--how is this file different from a .csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data\n",
    "\n",
    "In data analysis, there is a phase that precedes modeling and we call it <strong>exploratory analysis</strong>. This step involves familiarizing yourself with the data by checking the dimensions, understanding the variables, making visualizations and performing other sanity checks. Our last topic of the quarter will be data visualization with ggplot2, so let's cover the other ways we can explore our data.\n",
    "\n",
    "The list below are some tips that I have found very useful when I'm doing my exploratory analysis.\n",
    "<ul>\n",
    "    <li>\n",
    "    Use <code>dim()</code> to get the dimensions of the dataframe. The functions <code>summary()</code> and <code>glimpse()</code> are great for orienting yourself with a new dataset.\n",
    "    </li>\n",
    "    <li>\n",
    "    Always understand the units and range of your numeric variables. Similarly, understand the naming convention of factor levels within categorical variables.\n",
    "    </li>\n",
    "    <li>\n",
    "    Use <code>max()</code> and <code>min()</code> to check for odd values in numeric variables. And use <code>unique()</code> to check for incorrect levls in categorical variables.\n",
    "    </li>\n",
    "    <li>\n",
    "    <code>table()</code> is great for getting frequency counts of the factors within categorical variables. You can give it two categorical variables to get two-way tables as well.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Sunday</li>\n",
       "\t<li>Sundayoops!</li>\n",
       "\t<li>Mondayoops!</li>\n",
       "\t<li>Thursdayoops!</li>\n",
       "\t<li>Thursday</li>\n",
       "\t<li>Monday</li>\n",
       "\t<li>Saturday</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Sunday\n",
       "\\item Sundayoops!\n",
       "\\item Mondayoops!\n",
       "\\item Thursdayoops!\n",
       "\\item Thursday\n",
       "\\item Monday\n",
       "\\item Saturday\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Sunday\n",
       "2. Sundayoops!\n",
       "3. Mondayoops!\n",
       "4. Thursdayoops!\n",
       "5. Thursday\n",
       "6. Monday\n",
       "7. Saturday\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Sunday        Sundayoops!   Mondayoops!   Thursdayoops! Thursday     \n",
       "[6] Monday        Saturday     \n",
       "7 Levels: Monday Mondayoops! Saturday Sunday Sundayoops! ... Thursdayoops!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>123Pittsburgh</li>\n",
       "\t<li>St. Louis</li>\n",
       "\t<li>Indianapolis</li>\n",
       "\t<li>Washington</li>\n",
       "\t<li>San Francisco</li>\n",
       "\t<li>123Chicago</li>\n",
       "\t<li>Oakland</li>\n",
       "\t<li>Pittsburgh</li>\n",
       "\t<li>Kansas City</li>\n",
       "\t<li>Houston</li>\n",
       "\t<li>Baltimore</li>\n",
       "\t<li>San Diego</li>\n",
       "\t<li>Green Bay</li>\n",
       "\t<li>New York Jets</li>\n",
       "\t<li>Tennessee</li>\n",
       "\t<li>Buffalo</li>\n",
       "\t<li>Carolina</li>\n",
       "\t<li>Philadelphia</li>\n",
       "\t<li>Miami</li>\n",
       "\t<li>123Jacksonville</li>\n",
       "\t<li>Cincinnati</li>\n",
       "\t<li>123New England</li>\n",
       "\t<li>Arizona</li>\n",
       "\t<li>123Tennessee</li>\n",
       "\t<li>123Minnesota</li>\n",
       "\t<li>New York Giants</li>\n",
       "\t<li>123Oakland</li>\n",
       "\t<li>New Orleans</li>\n",
       "\t<li>123Cleveland</li>\n",
       "\t<li>Denver</li>\n",
       "\t<li>123Green Bay</li>\n",
       "\t<li>Chicago</li>\n",
       "\t<li>Detroit</li>\n",
       "\t<li>123Philadelphia</li>\n",
       "\t<li>Seattle</li>\n",
       "\t<li>123Dallas</li>\n",
       "\t<li>Jacksonville</li>\n",
       "\t<li>123Tampa Bay</li>\n",
       "\t<li>123Denver</li>\n",
       "\t<li>123Seattle</li>\n",
       "\t<li>123Atlanta</li>\n",
       "\t<li>Cleveland</li>\n",
       "\t<li>Minnesota</li>\n",
       "\t<li>123Houston</li>\n",
       "\t<li>123Baltimore</li>\n",
       "\t<li>123Detroit</li>\n",
       "\t<li>New England</li>\n",
       "\t<li>Atlanta</li>\n",
       "\t<li>Dallas</li>\n",
       "\t<li>123Indianapolis</li>\n",
       "\t<li>123Arizona</li>\n",
       "\t<li>123Miami</li>\n",
       "\t<li>Tampa Bay</li>\n",
       "\t<li>123San Francisco</li>\n",
       "\t<li>123New Orleans</li>\n",
       "\t<li>123Carolina</li>\n",
       "\t<li>123New York Jets</li>\n",
       "\t<li>123Washington</li>\n",
       "\t<li>123Cincinnati</li>\n",
       "\t<li>123New York Giants</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 123Pittsburgh\n",
       "\\item St. Louis\n",
       "\\item Indianapolis\n",
       "\\item Washington\n",
       "\\item San Francisco\n",
       "\\item 123Chicago\n",
       "\\item Oakland\n",
       "\\item Pittsburgh\n",
       "\\item Kansas City\n",
       "\\item Houston\n",
       "\\item Baltimore\n",
       "\\item San Diego\n",
       "\\item Green Bay\n",
       "\\item New York Jets\n",
       "\\item Tennessee\n",
       "\\item Buffalo\n",
       "\\item Carolina\n",
       "\\item Philadelphia\n",
       "\\item Miami\n",
       "\\item 123Jacksonville\n",
       "\\item Cincinnati\n",
       "\\item 123New England\n",
       "\\item Arizona\n",
       "\\item 123Tennessee\n",
       "\\item 123Minnesota\n",
       "\\item New York Giants\n",
       "\\item 123Oakland\n",
       "\\item New Orleans\n",
       "\\item 123Cleveland\n",
       "\\item Denver\n",
       "\\item 123Green Bay\n",
       "\\item Chicago\n",
       "\\item Detroit\n",
       "\\item 123Philadelphia\n",
       "\\item Seattle\n",
       "\\item 123Dallas\n",
       "\\item Jacksonville\n",
       "\\item 123Tampa Bay\n",
       "\\item 123Denver\n",
       "\\item 123Seattle\n",
       "\\item 123Atlanta\n",
       "\\item Cleveland\n",
       "\\item Minnesota\n",
       "\\item 123Houston\n",
       "\\item 123Baltimore\n",
       "\\item 123Detroit\n",
       "\\item New England\n",
       "\\item Atlanta\n",
       "\\item Dallas\n",
       "\\item 123Indianapolis\n",
       "\\item 123Arizona\n",
       "\\item 123Miami\n",
       "\\item Tampa Bay\n",
       "\\item 123San Francisco\n",
       "\\item 123New Orleans\n",
       "\\item 123Carolina\n",
       "\\item 123New York Jets\n",
       "\\item 123Washington\n",
       "\\item 123Cincinnati\n",
       "\\item 123New York Giants\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 123Pittsburgh\n",
       "2. St. Louis\n",
       "3. Indianapolis\n",
       "4. Washington\n",
       "5. San Francisco\n",
       "6. 123Chicago\n",
       "7. Oakland\n",
       "8. Pittsburgh\n",
       "9. Kansas City\n",
       "10. Houston\n",
       "11. Baltimore\n",
       "12. San Diego\n",
       "13. Green Bay\n",
       "14. New York Jets\n",
       "15. Tennessee\n",
       "16. Buffalo\n",
       "17. Carolina\n",
       "18. Philadelphia\n",
       "19. Miami\n",
       "20. 123Jacksonville\n",
       "21. Cincinnati\n",
       "22. 123New England\n",
       "23. Arizona\n",
       "24. 123Tennessee\n",
       "25. 123Minnesota\n",
       "26. New York Giants\n",
       "27. 123Oakland\n",
       "28. New Orleans\n",
       "29. 123Cleveland\n",
       "30. Denver\n",
       "31. 123Green Bay\n",
       "32. Chicago\n",
       "33. Detroit\n",
       "34. 123Philadelphia\n",
       "35. Seattle\n",
       "36. 123Dallas\n",
       "37. Jacksonville\n",
       "38. 123Tampa Bay\n",
       "39. 123Denver\n",
       "40. 123Seattle\n",
       "41. 123Atlanta\n",
       "42. Cleveland\n",
       "43. Minnesota\n",
       "44. 123Houston\n",
       "45. 123Baltimore\n",
       "46. 123Detroit\n",
       "47. New England\n",
       "48. Atlanta\n",
       "49. Dallas\n",
       "50. 123Indianapolis\n",
       "51. 123Arizona\n",
       "52. 123Miami\n",
       "53. Tampa Bay\n",
       "54. 123San Francisco\n",
       "55. 123New Orleans\n",
       "56. 123Carolina\n",
       "57. 123New York Jets\n",
       "58. 123Washington\n",
       "59. 123Cincinnati\n",
       "60. 123New York Giants\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 123Pittsburgh      St. Louis          Indianapolis       Washington        \n",
       " [5] San Francisco      123Chicago         Oakland            Pittsburgh        \n",
       " [9] Kansas City        Houston            Baltimore          San Diego         \n",
       "[13] Green Bay          New York Jets      Tennessee          Buffalo           \n",
       "[17] Carolina           Philadelphia       Miami              123Jacksonville   \n",
       "[21] Cincinnati         123New England     Arizona            123Tennessee      \n",
       "[25] 123Minnesota       New York Giants    123Oakland         New Orleans       \n",
       "[29] 123Cleveland       Denver             123Green Bay       Chicago           \n",
       "[33] Detroit            123Philadelphia    Seattle            123Dallas         \n",
       "[37] Jacksonville       123Tampa Bay       123Denver          123Seattle        \n",
       "[41] 123Atlanta         Cleveland          Minnesota          123Houston        \n",
       "[45] 123Baltimore       123Detroit         New England        Atlanta           \n",
       "[49] Dallas             123Indianapolis    123Arizona         123Miami          \n",
       "[53] Tampa Bay          123San Francisco   123New Orleans     123Carolina       \n",
       "[57] 123New York Jets   123Washington      123Cincinnati      123New York Giants\n",
       "60 Levels: 123Arizona 123Atlanta 123Baltimore 123Carolina ... Washington"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>n.</li>\n",
       "\t<li>nv</li>\n",
       "\t<li>nd</li>\n",
       "\t<li>n3</li>\n",
       "\t<li>yyy</li>\n",
       "\t<li>n2</li>\n",
       "\t<li>n1</li>\n",
       "\t<li>yree</li>\n",
       "\t<li>n</li>\n",
       "\t<li>y</li>\n",
       "\t<li>yw</li>\n",
       "\t<li>en</li>\n",
       "\t<li>een</li>\n",
       "\t<li>yy</li>\n",
       "\t<li>nn</li>\n",
       "\t<li>nnn</li>\n",
       "\t<li>3n</li>\n",
       "\t<li>y3</li>\n",
       "\t<li>3y</li>\n",
       "\t<li>n23</li>\n",
       "\t<li>n4</li>\n",
       "\t<li>n5t</li>\n",
       "\t<li>n654</li>\n",
       "\t<li>y2</li>\n",
       "\t<li>2y</li>\n",
       "\t<li>333n</li>\n",
       "\t<li>asdn</li>\n",
       "\t<li>ywow</li>\n",
       "\t<li>nsuch</li>\n",
       "\t<li>nshit</li>\n",
       "\t<li>ndata</li>\n",
       "\t<li>ynot</li>\n",
       "\t<li>yclean</li>\n",
       "\t<li>eeeeekkkkky</li>\n",
       "\t<li>lololn</li>\n",
       "\t<li>!!n</li>\n",
       "\t<li>nthis</li>\n",
       "\t<li>ntakes</li>\n",
       "\t<li>nforever</li>\n",
       "\t<li>nsomeone</li>\n",
       "\t<li>ybetter</li>\n",
       "\t<li>nlearn</li>\n",
       "\t<li>ythis</li>\n",
       "\t<li>yshit</li>\n",
       "\t<li>n!</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item n.\n",
       "\\item nv\n",
       "\\item nd\n",
       "\\item n3\n",
       "\\item yyy\n",
       "\\item n2\n",
       "\\item n1\n",
       "\\item yree\n",
       "\\item n\n",
       "\\item y\n",
       "\\item yw\n",
       "\\item en\n",
       "\\item een\n",
       "\\item yy\n",
       "\\item nn\n",
       "\\item nnn\n",
       "\\item 3n\n",
       "\\item y3\n",
       "\\item 3y\n",
       "\\item n23\n",
       "\\item n4\n",
       "\\item n5t\n",
       "\\item n654\n",
       "\\item y2\n",
       "\\item 2y\n",
       "\\item 333n\n",
       "\\item asdn\n",
       "\\item ywow\n",
       "\\item nsuch\n",
       "\\item nshit\n",
       "\\item ndata\n",
       "\\item ynot\n",
       "\\item yclean\n",
       "\\item eeeeekkkkky\n",
       "\\item lololn\n",
       "\\item !!n\n",
       "\\item nthis\n",
       "\\item ntakes\n",
       "\\item nforever\n",
       "\\item nsomeone\n",
       "\\item ybetter\n",
       "\\item nlearn\n",
       "\\item ythis\n",
       "\\item yshit\n",
       "\\item n!\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. n.\n",
       "2. nv\n",
       "3. nd\n",
       "4. n3\n",
       "5. yyy\n",
       "6. n2\n",
       "7. n1\n",
       "8. yree\n",
       "9. n\n",
       "10. y\n",
       "11. yw\n",
       "12. en\n",
       "13. een\n",
       "14. yy\n",
       "15. nn\n",
       "16. nnn\n",
       "17. 3n\n",
       "18. y3\n",
       "19. 3y\n",
       "20. n23\n",
       "21. n4\n",
       "22. n5t\n",
       "23. n654\n",
       "24. y2\n",
       "25. 2y\n",
       "26. 333n\n",
       "27. asdn\n",
       "28. ywow\n",
       "29. nsuch\n",
       "30. nshit\n",
       "31. ndata\n",
       "32. ynot\n",
       "33. yclean\n",
       "34. eeeeekkkkky\n",
       "35. lololn\n",
       "36. !!n\n",
       "37. nthis\n",
       "38. ntakes\n",
       "39. nforever\n",
       "40. nsomeone\n",
       "41. ybetter\n",
       "42. nlearn\n",
       "43. ythis\n",
       "44. yshit\n",
       "45. n!\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] n.          nv          nd          n3          yyy         n2         \n",
       " [7] n1          yree        n           y           yw          en         \n",
       "[13] een         yy          nn          nnn         3n          y3         \n",
       "[19] 3y          n23         n4          n5t         n654        y2         \n",
       "[25] 2y          333n        asdn        ywow        nsuch       nshit      \n",
       "[31] ndata       ynot        yclean      eeeeekkkkky lololn      !!n        \n",
       "[37] nthis       ntakes      nforever    nsomeone    ybetter     nlearn     \n",
       "[43] ythis       yshit       n!         \n",
       "45 Levels: !!n 2y 333n 3n 3y asdn eeeeekkkkky een en lololn n n! n. n1 ... yyy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(plyr)\n",
    "library(dplyr)\n",
    "\n",
    "# Get the dimensions of dirtyData\n",
    "\n",
    "#dim_ <- <FILL-IN>\n",
    "\n",
    "# Try using glimpse() (from the dplyr library) on dirtyData\n",
    "\n",
    "#<FILL-IN>\n",
    "\n",
    "# Get the summary of the arrests column\n",
    "\n",
    "#<FILL-IN>\n",
    "\n",
    "# Call unique() on the weekday, away team, and division game columns\n",
    "\n",
    "#uniqueWeek <- <FILL-IN>\n",
    "#uniqueTeam <- <FILL-IN>\n",
    "#uniqueDiv <- <FILL-IN>\n",
    "uniqueWeek <- unique(dirtyData$day_of_week)\n",
    "uniqueTeam <- unique(dirtyData$away_team)\n",
    "uniqueDiv <- unique(dirtyData$division_game)\n",
    "\n",
    "#dim_\n",
    "uniqueWeek\n",
    "uniqueTeam\n",
    "uniqueDiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some odd values in there! Using regular expressions, we can remove the incorrect characters from the strings.\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "<em>Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems.</em>\n",
    "\n",
    "Regular expressions define a syntax of characters that can be used to match patterns in strings. Moreover, they can be used by search algorithms to find matches, or even replace the matches with other characters. If you're observant, you noticed that the data above has some odd values--like \"oops!\" in <code>day_of_week</code> and 123 in <code>away_team</code>. We can use R's functions <code>grep()</code> and <code>grepl()</code> to find matches, or <code>gsub()</code> to replace matches with other characters.\n",
    "\n",
    "### Common Expressions and Characters\n",
    "\n",
    "We will only scatch the surface of regular expressions here. Last week's homework was to work through <a href=\"https://regexone.com\">regexone's tutorials</a>. If you didn't do that assignment, find a student that did to assist you. Let's take a look at some example regular expressions before diving into the syntax.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "        Expression\n",
    "        </td>\n",
    "        <td>\n",
    "        Matches\n",
    "        </td>\n",
    "        <td>\n",
    "        Example Matches (in <strong>bold</strong>)\n",
    "        </td>\n",
    "        <td>\n",
    "        Does not match\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            \"abc\"\n",
    "        </td>\n",
    "        <td>\n",
    "            \"abc\" literally\n",
    "        </td>\n",
    "        <td>\n",
    "            <strong>abc</strong>, z<strong>abc</strong>, <strong>abc</strong>red\n",
    "        </td>\n",
    "        <td>\n",
    "            acb\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            \"\\d\\d\\d\"\n",
    "        </td>\n",
    "        <td>\n",
    "            Sequence of any 3 uninterrupted digits.\n",
    "        </td>\n",
    "        <td>\n",
    "            <strong>123</strong>, <strong>805</strong>, <strong>415</strong>345, wow<strong>302</strong>such\n",
    "        </td>\n",
    "        <td>\n",
    "            word, wow, noNumbersHere!\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            \"[a-zA-Z]\"\n",
    "        </td>\n",
    "        <td>\n",
    "            Single letter, upper or lower case\n",
    "        </td>\n",
    "        <td>\n",
    "            2<strong>b</strong>4, <strong>w</strong>ww.wow.com, #&&2&3<strong>A</strong>\n",
    "        </td>\n",
    "        <td>\n",
    "            234, @@@@, 123\\_\\_405\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            \"[a-zA-Z]+\"\n",
    "        </td>\n",
    "        <td>\n",
    "            Sequence of letters, upper or lower case\n",
    "        </td>\n",
    "        <td>\n",
    "            0<strong>qwerty</strong>0, <strong>www</strong>.wow.com, #&&2&3<strong>Az</strong>2aa\n",
    "        </td>\n",
    "        <td>\n",
    "            234, @@@@, 123\\_\\_405\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            \"[^0-9]+\"\n",
    "        </td>\n",
    "        <td>\n",
    "            Sequence of characters not containing a digit\n",
    "        </td>\n",
    "        <td>\n",
    "            <strong>I'm at the </strong>805, <strong>onlyLetters</strong>, <strong>st</strong>0p, 0000<strong>onlyThis,Man!</strong>\n",
    "        </td>\n",
    "        <td>\n",
    "            123, 4158051122\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Let's cover some important characters in regular expressions.\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <strong>Metacharacters</strong> are characters that have special meaning. In regular expessions, some metacharacters are <code>[</code>, <code>]</code>, <code>^</code>, <code>.</code>, <code>|</code>, and <code>+</code>... just to name a few. These characters will not match their literal meaning (the substring, \"[ ]\", will <strong>not</strong> find \"[ ]\" in the string) and must be escaped with a \"\\\" if you want them to be literal.\n",
    "        <ul>\n",
    "            <li>\n",
    "                To find the substring <code>\"(1+1)\\*3=6\"</code> in a string, your regular expression would be <code>\"\\\\(1\\\\+1\\\\)\\\\*3=6\"</code> because \"(\", \")\", and \"+\" have special meaning when they are not escaped.\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Square Brackets</strong> will match their contents <strong>once</strong>. For example, \"<code>[jump]</code>\" will match a <strong>single</strong> character of \"j\", \"u\", \"m\", or \"p\". Not the string, \"jump\". But we can make some modifications...\n",
    "        <ul>\n",
    "            <li>\n",
    "                A caret, ^, inside the square brackets will make the expression match a single character <strong>not</strong> in the list. \"<code>[^jump]</code>\" will match any one character that is <strong>not</strong> \"j\", \"u\", \"m\", or \"p\".\n",
    "            </li>\n",
    "            <li>\n",
    "                An addition symbol, +, just outside the square brackets will make the expression match the bracketed list any number of times! \"<code>[jump]+</code>\" will match \"jump\", \"jjuummpp\", and \"ppmmjjuujj\".\n",
    "            </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>The Wildcard</strong> is the period. It will match <strong>any</strong> character, and should be used with care. \"<code>...</code>\" will match \"red\", \"_!^\" and \"<strong>blu</strong>e\".\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>The logical operator for \"<code>or</code>\" (\"<code>|</code>\")</strong>, still works within regular expressions. The expression, \"this|that\" will either match the literals \"this\" or \"that\" once in a string. \n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "### Regex Tips\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "    <strong>Do not make one big regular expression.</strong> Break down the regex into smaller, <em>more manageable</em>, problems. Use comments to help yourself keep track of the expressions.\n",
    "    </li>\n",
    "    <li>\n",
    "    <strong>Use [Regex101.com](https://regex101.com).</strong> This website will check your expression against sample text. The top right breaks down your regex character-by-character, letting you know what it is <em>and is not</em> capturing. In the bottom right, there is a small window with common tokens and expressions.\n",
    "    </li>\n",
    "    <li>\n",
    "    <strong>Test your regex.</strong> Double-check the expression worked by using it on examples where you know the expected outcome. \n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "### R's family of grep functions\n",
    "\n",
    "<strong>g/re/p</strong>: <em><strong>g</strong>lobally search a <strong>re</strong>gular expression and <strong>p</strong>rint.</em>\n",
    "\n",
    "R has a great collection of functions for regular expression operations right in its base library.\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <code>grep(<em>pattern, x, ignore.case, ...</em>)</code> searches for matches of the <code>pattern</code> in <code>x</code>. Similar functions like <code>regexpr(), gregexpr() and regexec()</code> provide the same general utility but differ in the amount of information returned. <code>grepl()</code> returns a logical.\n",
    "    </li>\n",
    "    <li>\n",
    "        <code>gsub(<em>pattern, replacement, x, ignore.case</em>)</code> will <strong>sub</strong>stitute any matches of <code>pattern</code> with the <code>replacement</code>. This is the function we will use to <em>clean</em> data, because we can remove any matches by simply replacing it with the empty string, \"\".\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"After cleaning... 1,2,3,4,5,6,7\"\n",
      "[1] \"After cleaning... 1,2,3,4,5,6,7\"\n"
     ]
    }
   ],
   "source": [
    "# Here's a vector that should only be numeric,\n",
    "# but there is some contamination.\n",
    "dirtyVector <- c(\"1\", \"2\", \"3q\", \"4r\", \"5we\", \"6butt\", \"7WOW\")\n",
    "\n",
    "# So we need to make a regex to match the letters\n",
    "r1 <- \"[a-zA-Z]\"\n",
    "\n",
    "# Pass r1 as the pattern, and the replacement is the empty string\n",
    "cleanedVector <- gsub(pattern=r1, replacement=\"\", x=dirtyVector)\n",
    "\n",
    "# Notice that I coerced the vector to a numeric without any errors\n",
    "print(paste(\"After cleaning...\", paste(as.numeric(cleanedVector), collapse=\",\")))\n",
    "\n",
    "# Now an even dirtier vector that should be numeric\n",
    "dirtyVector <- c(\"1..\", \"qq2\", \"3ere\", \"4ee\", \"(5)\", \"6'er\", \"~7~\")\n",
    "\n",
    "# Same process... what is r2 matching?\n",
    "r2 <- \"[^0-9]+\"\n",
    "cleanedVector <- gsub(pattern=r2, replacement=\"\", x=dirtyVector)\n",
    "print(paste(\"After cleaning...\", paste(as.numeric(cleanedVector), collapse=\",\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Loading static data is a trivial process, so the exercises will focus on cleaning data with regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'thereisacodeinhere'"
      ],
      "text/latex": [
       "'thereisacodeinhere'"
      ],
      "text/markdown": [
       "'thereisacodeinhere'"
      ],
      "text/plain": [
       "[1] \"thereisacodeinhere\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirtyString <- \"tzqhzerexwixzsazcqxodezwixnhzqexrwzexzqxz\"\n",
    "\n",
    "# Use gsub to remove all z, x, q, and w from dirtyString. \n",
    "# Should be done in one line.\n",
    "\n",
    "#cleanstring <- gsub(<FILLIN>)\n",
    "cleanString <- gsub(pattern = \"[zxqw]\", replace=\"\", x=dirtyVector)\n",
    "\n",
    "cleanString\n",
    "stopifnot(nchar(cleanString) == 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'wowsuchr'"
      ],
      "text/latex": [
       "'wowsuchr'"
      ],
      "text/markdown": [
       "'wowsuchr'"
      ],
      "text/plain": [
       "[1] \"wowsuchr\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirtyString <- \"kyWk3low4ySuy6ykch4kR1l\"\n",
    "\n",
    "# Remove all characters except the following:\n",
    "# r, h, c, u, o, s, w\n",
    "# Force the entire string to lowercase before filtering.\n",
    "\n",
    "#lowerCaseString <- <FILLIN>\n",
    "#cleanString <- <FILLIN>\n",
    "\n",
    "lowerCaseString <- tolower(dirtyString)\n",
    "cleanString <- gsub(pattern = \"[^rhcuosw]\", replacement = \"\", x = lowerCaseString)\n",
    "\n",
    "cleanString\n",
    "stopifnot(nchar(cleanString) == 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'github'</li>\n",
       "\t<li>'DataCamp'</li>\n",
       "\t<li>'facebook'</li>\n",
       "\t<li>'reddit'</li>\n",
       "\t<li>'youtube'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'github'\n",
       "\\item 'DataCamp'\n",
       "\\item 'facebook'\n",
       "\\item 'reddit'\n",
       "\\item 'youtube'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'github'\n",
       "2. 'DataCamp'\n",
       "3. 'facebook'\n",
       "4. 'reddit'\n",
       "5. 'youtube'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"github\"   \"DataCamp\" \"facebook\" \"reddit\"   \"youtube\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history <- c(\"www.github.com\",\n",
    "             \"www.DataCamp.com\",\n",
    "             \"www.facebook.com\",\n",
    "             \"www.reddit.com\",\n",
    "             \"www.youtube.com\")\n",
    "\n",
    "# In \"history\", filter the URLs to only the first part of the domain name.\n",
    "# For example, \"www.reddit.com\" would be \"reddit\".\n",
    "\n",
    "domains <- gsub(\"www.|.com\", replacement = \"\", x = history)\n",
    "domains\n",
    "\n",
    "stopifnot(domains[2] == \"DataCamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up that dirty NFL dataset. The work flow is mostly the same, but you will need to reassign the column. Normally it would be done like this...\n",
    "\n",
    "<code>dataframe$colName <- gsub(\"[chars]+\\.\", replacement=\"\", x=dataframe$colName)</code>\n",
    "\n",
    "<strong>...But</strong> this can be dangerous when you're just learning. If you accidentally capture everything (with something like <code>\".+\"</code> then you'll erase everything in the column and need to reload the data!\n",
    "\n",
    "To avoid this, I copied the dirty NFL dataframe, <code>dirtyData</code> to a new frame called <code>practice</code>. If you make a mistake, just re-run the code chunk below to reset the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice <- dirtyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Sunday'</li>\n",
       "\t<li>'Monday'</li>\n",
       "\t<li>'Thursday'</li>\n",
       "\t<li>'Saturday'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Sunday'\n",
       "\\item 'Monday'\n",
       "\\item 'Thursday'\n",
       "\\item 'Saturday'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Sunday'\n",
       "2. 'Monday'\n",
       "3. 'Thursday'\n",
       "4. 'Saturday'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Sunday\"   \"Monday\"   \"Thursday\" \"Saturday\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clean the day_of_week column so the days are properly spelled\n",
    "\n",
    "#practice$day_of_week <- <FILLIN>\n",
    "practice$day_of_week <- gsub(pattern = \"oops!\", replacement=\"\", x=practice$day_of_week)\n",
    "\n",
    "unique(practice$day_of_week)\n",
    "stopifnot(length(unique(practice$day_of_week)) == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Pittsburgh'</li>\n",
       "\t<li>'St. Louis'</li>\n",
       "\t<li>'Indianapolis'</li>\n",
       "\t<li>'Washington'</li>\n",
       "\t<li>'San Francisco'</li>\n",
       "\t<li>'Chicago'</li>\n",
       "\t<li>'Oakland'</li>\n",
       "\t<li>'Kansas City'</li>\n",
       "\t<li>'Houston'</li>\n",
       "\t<li>'Baltimore'</li>\n",
       "\t<li>'San Diego'</li>\n",
       "\t<li>'Green Bay'</li>\n",
       "\t<li>'New York Jets'</li>\n",
       "\t<li>'Tennessee'</li>\n",
       "\t<li>'Buffalo'</li>\n",
       "\t<li>'Carolina'</li>\n",
       "\t<li>'Philadelphia'</li>\n",
       "\t<li>'Miami'</li>\n",
       "\t<li>'Jacksonville'</li>\n",
       "\t<li>'Cincinnati'</li>\n",
       "\t<li>'New England'</li>\n",
       "\t<li>'Arizona'</li>\n",
       "\t<li>'Minnesota'</li>\n",
       "\t<li>'New York Giants'</li>\n",
       "\t<li>'New Orleans'</li>\n",
       "\t<li>'Cleveland'</li>\n",
       "\t<li>'Denver'</li>\n",
       "\t<li>'Detroit'</li>\n",
       "\t<li>'Seattle'</li>\n",
       "\t<li>'Dallas'</li>\n",
       "\t<li>'Tampa Bay'</li>\n",
       "\t<li>'Atlanta'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Pittsburgh'\n",
       "\\item 'St. Louis'\n",
       "\\item 'Indianapolis'\n",
       "\\item 'Washington'\n",
       "\\item 'San Francisco'\n",
       "\\item 'Chicago'\n",
       "\\item 'Oakland'\n",
       "\\item 'Kansas City'\n",
       "\\item 'Houston'\n",
       "\\item 'Baltimore'\n",
       "\\item 'San Diego'\n",
       "\\item 'Green Bay'\n",
       "\\item 'New York Jets'\n",
       "\\item 'Tennessee'\n",
       "\\item 'Buffalo'\n",
       "\\item 'Carolina'\n",
       "\\item 'Philadelphia'\n",
       "\\item 'Miami'\n",
       "\\item 'Jacksonville'\n",
       "\\item 'Cincinnati'\n",
       "\\item 'New England'\n",
       "\\item 'Arizona'\n",
       "\\item 'Minnesota'\n",
       "\\item 'New York Giants'\n",
       "\\item 'New Orleans'\n",
       "\\item 'Cleveland'\n",
       "\\item 'Denver'\n",
       "\\item 'Detroit'\n",
       "\\item 'Seattle'\n",
       "\\item 'Dallas'\n",
       "\\item 'Tampa Bay'\n",
       "\\item 'Atlanta'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Pittsburgh'\n",
       "2. 'St. Louis'\n",
       "3. 'Indianapolis'\n",
       "4. 'Washington'\n",
       "5. 'San Francisco'\n",
       "6. 'Chicago'\n",
       "7. 'Oakland'\n",
       "8. 'Kansas City'\n",
       "9. 'Houston'\n",
       "10. 'Baltimore'\n",
       "11. 'San Diego'\n",
       "12. 'Green Bay'\n",
       "13. 'New York Jets'\n",
       "14. 'Tennessee'\n",
       "15. 'Buffalo'\n",
       "16. 'Carolina'\n",
       "17. 'Philadelphia'\n",
       "18. 'Miami'\n",
       "19. 'Jacksonville'\n",
       "20. 'Cincinnati'\n",
       "21. 'New England'\n",
       "22. 'Arizona'\n",
       "23. 'Minnesota'\n",
       "24. 'New York Giants'\n",
       "25. 'New Orleans'\n",
       "26. 'Cleveland'\n",
       "27. 'Denver'\n",
       "28. 'Detroit'\n",
       "29. 'Seattle'\n",
       "30. 'Dallas'\n",
       "31. 'Tampa Bay'\n",
       "32. 'Atlanta'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Pittsburgh\"      \"St. Louis\"       \"Indianapolis\"    \"Washington\"     \n",
       " [5] \"San Francisco\"   \"Chicago\"         \"Oakland\"         \"Kansas City\"    \n",
       " [9] \"Houston\"         \"Baltimore\"       \"San Diego\"       \"Green Bay\"      \n",
       "[13] \"New York Jets\"   \"Tennessee\"       \"Buffalo\"         \"Carolina\"       \n",
       "[17] \"Philadelphia\"    \"Miami\"           \"Jacksonville\"    \"Cincinnati\"     \n",
       "[21] \"New England\"     \"Arizona\"         \"Minnesota\"       \"New York Giants\"\n",
       "[25] \"New Orleans\"     \"Cleveland\"       \"Denver\"          \"Detroit\"        \n",
       "[29] \"Seattle\"         \"Dallas\"          \"Tampa Bay\"       \"Atlanta\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The \"away_team\" column is littered with unnecessary numbers.\n",
    "# Get rid of them!\n",
    "\n",
    "# practice$away_team <- <FILLIN>\n",
    "practice$away_team <- gsub(pattern=\"[123]+\", replacement=\"\", x=practice$away_team)\n",
    "\n",
    "unique(practice$away_team)\n",
    "stopifnot(length(unique(practice$away_team)) == 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>n.</li>\n",
       "\t<li>nv</li>\n",
       "\t<li>nd</li>\n",
       "\t<li>n3</li>\n",
       "\t<li>yyy</li>\n",
       "\t<li>n2</li>\n",
       "\t<li>n1</li>\n",
       "\t<li>yree</li>\n",
       "\t<li>n</li>\n",
       "\t<li>y</li>\n",
       "\t<li>yw</li>\n",
       "\t<li>en</li>\n",
       "\t<li>een</li>\n",
       "\t<li>yy</li>\n",
       "\t<li>nn</li>\n",
       "\t<li>nnn</li>\n",
       "\t<li>3n</li>\n",
       "\t<li>y3</li>\n",
       "\t<li>3y</li>\n",
       "\t<li>n23</li>\n",
       "\t<li>n4</li>\n",
       "\t<li>n5t</li>\n",
       "\t<li>n654</li>\n",
       "\t<li>y2</li>\n",
       "\t<li>2y</li>\n",
       "\t<li>333n</li>\n",
       "\t<li>asdn</li>\n",
       "\t<li>ywow</li>\n",
       "\t<li>nsuch</li>\n",
       "\t<li>nshit</li>\n",
       "\t<li>ndata</li>\n",
       "\t<li>ynot</li>\n",
       "\t<li>yclean</li>\n",
       "\t<li>eeeeekkkkky</li>\n",
       "\t<li>lololn</li>\n",
       "\t<li>!!n</li>\n",
       "\t<li>nthis</li>\n",
       "\t<li>ntakes</li>\n",
       "\t<li>nforever</li>\n",
       "\t<li>nsomeone</li>\n",
       "\t<li>ybetter</li>\n",
       "\t<li>nlearn</li>\n",
       "\t<li>ythis</li>\n",
       "\t<li>yshit</li>\n",
       "\t<li>n!</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item n.\n",
       "\\item nv\n",
       "\\item nd\n",
       "\\item n3\n",
       "\\item yyy\n",
       "\\item n2\n",
       "\\item n1\n",
       "\\item yree\n",
       "\\item n\n",
       "\\item y\n",
       "\\item yw\n",
       "\\item en\n",
       "\\item een\n",
       "\\item yy\n",
       "\\item nn\n",
       "\\item nnn\n",
       "\\item 3n\n",
       "\\item y3\n",
       "\\item 3y\n",
       "\\item n23\n",
       "\\item n4\n",
       "\\item n5t\n",
       "\\item n654\n",
       "\\item y2\n",
       "\\item 2y\n",
       "\\item 333n\n",
       "\\item asdn\n",
       "\\item ywow\n",
       "\\item nsuch\n",
       "\\item nshit\n",
       "\\item ndata\n",
       "\\item ynot\n",
       "\\item yclean\n",
       "\\item eeeeekkkkky\n",
       "\\item lololn\n",
       "\\item !!n\n",
       "\\item nthis\n",
       "\\item ntakes\n",
       "\\item nforever\n",
       "\\item nsomeone\n",
       "\\item ybetter\n",
       "\\item nlearn\n",
       "\\item ythis\n",
       "\\item yshit\n",
       "\\item n!\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. n.\n",
       "2. nv\n",
       "3. nd\n",
       "4. n3\n",
       "5. yyy\n",
       "6. n2\n",
       "7. n1\n",
       "8. yree\n",
       "9. n\n",
       "10. y\n",
       "11. yw\n",
       "12. en\n",
       "13. een\n",
       "14. yy\n",
       "15. nn\n",
       "16. nnn\n",
       "17. 3n\n",
       "18. y3\n",
       "19. 3y\n",
       "20. n23\n",
       "21. n4\n",
       "22. n5t\n",
       "23. n654\n",
       "24. y2\n",
       "25. 2y\n",
       "26. 333n\n",
       "27. asdn\n",
       "28. ywow\n",
       "29. nsuch\n",
       "30. nshit\n",
       "31. ndata\n",
       "32. ynot\n",
       "33. yclean\n",
       "34. eeeeekkkkky\n",
       "35. lololn\n",
       "36. !!n\n",
       "37. nthis\n",
       "38. ntakes\n",
       "39. nforever\n",
       "40. nsomeone\n",
       "41. ybetter\n",
       "42. nlearn\n",
       "43. ythis\n",
       "44. yshit\n",
       "45. n!\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] n.          nv          nd          n3          yyy         n2         \n",
       " [7] n1          yree        n           y           yw          en         \n",
       "[13] een         yy          nn          nnn         3n          y3         \n",
       "[19] 3y          n23         n4          n5t         n654        y2         \n",
       "[25] 2y          333n        asdn        ywow        nsuch       nshit      \n",
       "[31] ndata       ynot        yclean      eeeeekkkkky lololn      !!n        \n",
       "[37] nthis       ntakes      nforever    nsomeone    ybetter     nlearn     \n",
       "[43] ythis       yshit       n!         \n",
       "45 Levels: !!n 2y 333n 3n 3y asdn eeeeekkkkky een en lololn n n! n. n1 ... yyy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>''</li>\n",
       "\t<li>'nn'</li>\n",
       "\t<li>'n'</li>\n",
       "\t<li>'ny'</li>\n",
       "\t<li>'nnn'</li>\n",
       "\t<li>'y'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item ''\n",
       "\\item 'nn'\n",
       "\\item 'n'\n",
       "\\item 'ny'\n",
       "\\item 'nnn'\n",
       "\\item 'y'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. ''\n",
       "2. 'nn'\n",
       "3. 'n'\n",
       "4. 'ny'\n",
       "5. 'nnn'\n",
       "6. 'y'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"\"    \"nn\"  \"n\"   \"ny\"  \"nnn\" \"y\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The \"division_game\" column should only contain \"y\" and \"n\"\n",
    "# But it's littered with a lot of extra characters, clean it!\n",
    "unique(practice$division_game)\n",
    "practice$division_game <- gsub(pattern=\"[^yn]\", replacement=\"\", x=practice$away_team)\n",
    "\n",
    "unique(practice$division_game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'github'</li>\n",
       "\t<li>'DataCamp'</li>\n",
       "\t<li>'facebook'</li>\n",
       "\t<li>'reddit'</li>\n",
       "\t<li>'JSON'</li>\n",
       "\t<li>'jasonfreeberg'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'github'\n",
       "\\item 'DataCamp'\n",
       "\\item 'facebook'\n",
       "\\item 'reddit'\n",
       "\\item 'JSON'\n",
       "\\item 'jasonfreeberg'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'github'\n",
       "2. 'DataCamp'\n",
       "3. 'facebook'\n",
       "4. 'reddit'\n",
       "5. 'JSON'\n",
       "6. 'jasonfreeberg'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"github\"        \"DataCamp\"      \"facebook\"      \"reddit\"       \n",
       "[5] \"JSON\"          \"jasonfreeberg\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history2 <- c(\"http://www.github.com\",\n",
    "             \"https://www.DataCamp.com\",\n",
    "             \"www.facebook.com\",\n",
    "             \"www.reddit.com\",\n",
    "             \"www.JSON.org\",\n",
    "             \"github.jasonfreeberg.io\")\n",
    "\n",
    "# Same problem as the previous list of URLs, harder strings! This is \n",
    "# a difficult problem, so don't spend too long on it. I had better \n",
    "# luck using str_replace() from the stringr library.\n",
    "\n",
    "library(stringr)\n",
    "\n",
    "#domains2 <- str_replace(pattern=\"<FILLIN>\", string=history2, replacement=\"\")\n",
    "domains2 <- str_replace(pattern=\"([^.]*\\\\.)\", string=history2, replacement=\"\")\n",
    "domains2 <- str_replace(pattern=\"\\\\..*\", string=domains2, replacement=\"\")\n",
    "\n",
    "domains2\n",
    "stopifnot(domains2[2] == \"DataCamp\")\n",
    "# Hint: Do it in two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You're done with tonight's exercises! Check [the syllabus](https://github.com/JasonFreeberg/R_Tutorials/blob/master/README.md) for this week's homework. And don't forget... *if you're going through hell, you keep going.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
